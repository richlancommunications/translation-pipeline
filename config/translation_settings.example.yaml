# Translation Pipeline Configuration
# Copy this file to translation_settings.yaml and fill in your values
# DO NOT commit translation_settings.yaml to version control

translation:
  # Default language settings
  default_source_lang: "en"
  default_target_lang: "sw"
  
  # Supported language pairs
  language_pairs:
    - source: "en"
      target: "sw"
      glossary: "glossaries/medical_terms.json"
    - source: "en"
      target: "am"  # Amharic (example)
      glossary: "glossaries/medical_terms_am.json"
  
  # Translation engines
  engines:
    google_translate:
      enabled: true
      api_key: "YOUR_GOOGLE_API_KEY_HERE"
      project_id: "your-project-id"
      rate_limit: 100  # requests per minute
      
    ollama:
      enabled: true
      base_url: "http://localhost:11434"
      model: "mistral"
      timeout: 120
      fallback_on_error: true
    
    # Primary engine selection
    primary_engine: "ollama"
    fallback_engine: "google_translate"
  
  # Quality settings
  quality:
    min_confidence_threshold: 0.70
    enable_qa_checks: true
    require_glossary_match: false
    log_low_confidence: true
    
  # Processing settings
  processing:
    enable_cache: true
    cache_ttl: 86400  # 24 hours in seconds
    batch_size: 10
    parallel_workers: 4
    preserve_formatting: true
    
  # Output settings
  output:
    include_metadata: true
    generate_qa_report: true
    save_translation_memory: true
    output_directory: "translated"

# Logging configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: "data/logs/translation.log"
  max_size: 10485760  # 10MB
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Advanced settings
advanced:
  # Translation memory settings
  translation_memory:
    enabled: true
    database: "data/translation_memory/tm.db"
    fuzzy_match_threshold: 0.85
    
  # Glossary settings
  glossary:
    auto_update: false
    validation_on_load: true
    case_sensitive: false
    
  # Performance settings
  performance:
    max_workers: 4
    chunk_size: 1000  # words per chunk
    timeout: 300  # seconds